{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58053409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '/Users/grahamseamans/classes/data_science/ds-project/src/util.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imp\n",
    "\n",
    "import data\n",
    "import util\n",
    "\n",
    "imp.reload(data)\n",
    "imp.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cf39ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = data.get_transit_daily()\n",
    "# gets a smaller version for faster troubleshooting\n",
    "daily = data.data_transforms(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3372e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = daily[data.USED_COLS + [\"trip_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9da56f-f1e6-425c-a5ed-c74180768bd8",
   "metadata": {},
   "source": [
    "so how does this work:\n",
    "* each stop gets its own row\n",
    "* get a list with every stop\n",
    "* isolate each trip (get a list with every trip, pull out the trip one at a time)\n",
    "* for each stop, check the trip table, add that row to the image, or dont if there's nothing there\n",
    "* sort them by arrive time somehow?\n",
    "* maybe I get them out of the gtfs data instead...\n",
    "* maybe do something else with the categorical data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "014db676-b7fb-4dfb-9698-290e29ce4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_ids = daily[\"trip_id\"].unique().to_list()\n",
    "df = x\n",
    "\n",
    "non_categories = list(set(data.USED_COLS) - set(data.CATEGORIES))\n",
    "iding_the_row = [\"trip_id\", \"direction\", \"stop_id\"]\n",
    "for_image = df[non_categories + iding_the_row]\n",
    "\n",
    "trip_images = []\n",
    "trip_labels = []\n",
    "\n",
    "for trip_id in trip_ids:\n",
    "    trip = for_image[for_image[\"trip_id\"] == trip_id]\n",
    "\n",
    "    stop_id_list = []\n",
    "\n",
    "    if trip.iloc[0][\"direction\"] == 0:\n",
    "        stop_id_list = data.DIR_0_STOP_IDS\n",
    "        #     else:\n",
    "        #         stop_id_list = data.DIR_1_STOP_IDS\n",
    "\n",
    "        image = np.zeros((len(stop_id_list), len(non_categories) + 1))\n",
    "        label = np.zeros((len(stop_id_list)))\n",
    "\n",
    "        for i, stop_id in enumerate(stop_id_list):\n",
    "            row = trip[trip[\"stop_id\"] == stop_id][\n",
    "                [\"label\"] + non_categories\n",
    "            ].to_numpy()\n",
    "            if row.shape[0] > 0:\n",
    "                row = row[0]\n",
    "                image[i] = row\n",
    "                label[i] = row[0]\n",
    "\n",
    "        trip_images.append(image)\n",
    "        trip_labels.append(label)\n",
    "        np.set_printoptions(precision=1, suppress=True)\n",
    "\n",
    "trip_images = np.stack(trip_images, axis=0)\n",
    "trip_labels = np.stack(trip_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "792d3241-7703-40b9-a867-35ae486d5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.get_dummies(x)  # turns all categoricals into one hot encoded columns!\n",
    "\n",
    "label = x.pop(\"label\")\n",
    "x = trip_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d362e2d3-a311-43bd-87e4-44fc653c1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 80)\n",
      "(73, 80, 11)\n"
     ]
    }
   ],
   "source": [
    "print(trip_labels.shape)\n",
    "print(trip_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b130a313-18e1-4c55-863d-b30594c797e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  71.   61.   58. ...  -31.  -39.    0.]\n",
      " [  86.   42.   19. ...    1.  -18.    0.]\n",
      " [ 132.  132.  129. ... -187. -181.    0.]\n",
      " ...\n",
      " [ 100.   67.  105. ... -183.    0.    0.]\n",
      " [ 200.  156.  153. ... -176.    0.    0.]\n",
      " [  71.   27.   37. ...    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "util.big_print(trip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd0e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of input features:  568\n"
     ]
    }
   ],
   "source": [
    "print(\"number of input features: \", len(sorted(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2189e845",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-31c982964523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.8/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Externally in opensource we must enable exceptions to load the shared object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "# if batch size is one the net freaks out (maybe traning, maybe testing, either way, it's bad)\n",
    "batch_size = 50\n",
    "data_len = len(x)\n",
    "train = 0.8\n",
    "val = 0.1\n",
    "test = 0.1\n",
    "\n",
    "assert train + val + test == 1\n",
    "\n",
    "train_size = int(train * data_len)\n",
    "val_size = int(val * data_len)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x.values, label.values))\n",
    "\n",
    "# only shuffles the training set\n",
    "train_dataset = dataset.take(train_size).shuffle(train_size).batch(batch_size)\n",
    "val_dataset = dataset.skip(train_size).take(val_size).batch(batch_size)\n",
    "test_dataset = dataset.skip(train_size).skip(val_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(500, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "            #             tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.MeanSquaredError(\n",
    "            reduction=\"auto\", name=\"mean_squared_error\"\n",
    "        ),\n",
    "        metrics=[\"accuracy\", \"mean_absolute_error\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00907bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_absolute_error\", patience=10, restore_best_weights=True\n",
    ")\n",
    "model.fit(train_dataset, epochs=100, validation_data=val_dataset, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7420fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aef57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for data in test_dataset:\n",
    "    preds.append(model.predict_on_batch(data[0]).flatten())\n",
    "    labels.append(data[1])\n",
    "\n",
    "preds = [p.tolist() for p in preds]\n",
    "labels = [l.numpy().tolist() for l in labels]\n",
    "\n",
    "preds = util.flatten(preds)\n",
    "labels = util.flatten(labels)\n",
    "assert len(preds) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# adjust these numbers to change the width and height of the plot!\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 7]\n",
    "\n",
    "util.plot(69, 420, preds, labels)\n",
    "\n",
    "util.allDone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
